{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WesleySantosMaxtelll/doutorado/blob/main/MoE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xdgl4XM_IkH",
        "outputId": "da022cf2-9be3-4880-af4f-a28c4b0f93c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m122.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.0 tokenizers-0.13.2 transformers-4.26.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.7.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZb6BLR5EAeo",
        "outputId": "f22ce7bd-10d1-4b05-bb40-fd7bb0d6eb18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuscucC8SZcV"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import ast\n",
        "import pandas as pd\n",
        "import torch\n",
        "import os\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW, SGD\n",
        "from transformers import BertTokenizerFast, BertModel, DistilBertTokenizer, DistilBertModel\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, Dataset\n",
        "from sklearn.utils import class_weight\n",
        "from collections import Counter\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import _pickle as pickle\n",
        "import time\n",
        "from datetime import datetime, timedelta\n",
        "import gc\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from tqdm import tqdm\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvxO2DSQWAW_"
      },
      "outputs": [],
      "source": [
        "\n",
        "def load_data(portion, task, sel):\n",
        "    df_c = pd.read_csv(f'/content/drive/MyDrive/doutorado/dados_v6/full/{task}/{portion}_{task}_c_SetembroBR_v6.csv', sep=';')\n",
        "    df_d = pd.read_csv(f'/content/drive/MyDrive/doutorado/dados_v6/full/{task}/{portion}_{task}_SetembroBR_v6.csv', sep=';')\n",
        "    df_c_net = pd.read_csv(f'/content/drive/MyDrive/doutorado/dados_v6/full/{task}/{task}_ctrl-users-network_final_v6.csv', sep=';')\n",
        "    df_d_net = pd.read_csv(f'/content/drive/MyDrive/doutorado/dados_v6/full/{task}/{task}_diag-users-network_final_v6.csv', sep=';')\n",
        "    if sel not in ['all', 'all_br', 'balanced', 'medical_terms', 'pref_medical_terms', 'r80', 'dev80', 'r100']:  \n",
        "        df_d = df_d[df_d['User_ID'].isin(df_d_net[df_d_net['Event_Type'] == sel]['User_ID'])]\n",
        "        df_c_net = df_c_net[df_c_net['Counterpart'].isin(df_d['User_ID'])]\n",
        "        df_c = df_c[df_c['User_ID'].isin(df_c_net['User_ID'])]\n",
        "    if sel == 'balanced' and portion == 'train':\n",
        "        # return df_c, df_d, df_c_net\n",
        "        dt = {'D':'depression', 'A': 'anxiety'}\n",
        "        user_id_c_all = []\n",
        "        for _, user_id in df_d.iterrows():\n",
        "            user_id_c = df_c_net[df_c_net['Counterpart'] == user_id['User_ID']].sample(n=1).iloc[0]['User_ID']\n",
        "            user_id_c_all.append(user_id_c)\n",
        "        df_c = df_c[df_c['User_ID'].isin(set(user_id_c_all))] \n",
        "    return pd.concat((df_c, df_d))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FttGVbX1quGy"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "# filter medical terms\n",
        "def makeTags(text):\n",
        "    text = str(text).lower()\n",
        "    if re.search(r\"diagn[oó]stic\", text, flags=re.DOTALL):\n",
        "        return 'diagnostico'\n",
        "    if re.search(r\"tratamento\", text, flags=re.DOTALL):\n",
        "        return 'tratamento'\n",
        "    if re.search(r\"depress[aã]o\", text, flags=re.DOTALL):\n",
        "        return 'depressao'\n",
        "    if re.search(r\"ansiedade\", text, flags=re.DOTALL):\n",
        "            return 'ansiedade'\n",
        "    if re.search(r\"depressivo|tarja\\sp|ansiol[íi]tico\", text, flags=re.DOTALL):\n",
        "        return 'antidepress'\n",
        "    if re.search(r\"m[eé]dic[oa]|psic[oó]l[oó]g[oa]|psiquiatra|neurologista|terapeuta\", text, flags=re.DOTALL):\n",
        "        return 'medico'\n",
        "    return ''\n",
        "\n",
        "def HasMeds(text):\n",
        "    text = str(text).lower()\n",
        "    terms = r'(hospital|cl[ií]nic|depr[eê]|m[eé]dic[oa]|psic[oó]log[oa]|psiquiatra|neurologista|\\bterapeuta|\\bterapia|rem[ée]dio|medicamento|medica[çc][aã]o|depress[aã]o|ansiedade|anti-depressivo|depressivo|tarja\\sp|ansiol[íi]tico|escitalopran|amitriptilina|sertralina|citalopram|fluoxetina)'\n",
        "    if re.search(terms, text, flags=re.DOTALL):\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def filter_medical_terms(texts):\n",
        "    sel_texts_ = []\n",
        "    for text_list in tqdm(texts):\n",
        "        sel_texts = [tt for tt in text_list if makeTags(tt) == '']\n",
        "        sel_texts_.append(sel_texts)\n",
        "    return sel_texts_\n",
        "\n",
        "\n",
        "def sel_medical_terms(texts):\n",
        "    size = 100\n",
        "    sel_texts_ = []\n",
        "    for text_list in tqdm(texts):\n",
        "        sel_texts = [tt for tt in text_list if makeTags(tt) == '']\n",
        "        med_sel_texts = [tt for tt in text_list if makeTags(tt) != '']\n",
        "        if size <= len(med_sel_texts):\n",
        "            sel_texts_.append(med_sel_texts[-size:])\n",
        "        else:\n",
        "            l = size - len(med_sel_texts)\n",
        "            # print(l)\n",
        "            if len(sel_texts) > l:\n",
        "                add_texts = random.sample(sel_texts, l)\n",
        "                med_sel_texts = med_sel_texts + add_texts\n",
        "                random.shuffle(med_sel_texts)\n",
        "                sel_texts_.append(med_sel_texts)\n",
        "            else:\n",
        "                sel_texts_.append(med_sel_texts + sel_texts)\n",
        "\n",
        "    return sel_texts_\n",
        "  \n",
        "def random_cont_selection(texts, n=80):\n",
        "    sel_texts_ = []\n",
        "    for text_list in tqdm(texts):\n",
        "        if len(text_list) > n + 1:\n",
        "            fp = random.randint(n, len(text_list))\n",
        "            sp = fp - n\n",
        "        else:\n",
        "            sp = 0\n",
        "            fp = len(text_list)\n",
        "        sel_texts_.append(text_list[sp:fp])\n",
        "\n",
        "    return sel_texts_\n",
        "\n",
        "def recent_selection(texts, n=80):\n",
        "    sel_texts_ = []\n",
        "    for text_list in tqdm(texts):\n",
        "        sel_texts_.append(text_list[-n:])\n",
        "\n",
        "    return sel_texts_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5geqgMsYO27"
      },
      "outputs": [],
      "source": [
        "def load_convert(task, sel):\n",
        "    df_test = load_data('test', task, sel)\n",
        "    df_train = load_data('train', task, sel)\n",
        "    df_test['Text'] = df_test['Text'].apply(lambda x: x.split('#'))\n",
        "    df_test['label'] = df_test['Diagnosed_YN'].apply(lambda x: 1 if x == 'yes' else 0)\n",
        "    df_train['Text'] = df_train['Text'].apply(lambda x: x.split('#'))\n",
        "    df_train['label'] = df_train['Diagnosed_YN'].apply(lambda x: 1 if x == 'yes' else 0)\n",
        "    train_initial_size = df_train['Text'].apply(lambda x: len(x)).sum()\n",
        "    test_initial_size = df_test['Text'].apply(lambda x: len(x)).sum()\n",
        "    random.seed(42)\n",
        "    if sel == 'medical_terms': \n",
        "        print('Start filter')\n",
        "        df_train['Text'] = filter_medical_terms(df_train['Text'])\n",
        "        df_test['Text'] = filter_medical_terms(df_test['Text'])\n",
        "        train_final_size = df_train['Text'].apply(lambda x: len(x)).sum()\n",
        "        test_final_size = df_test['Text'].apply(lambda x: len(x)).sum()\n",
        "        print(f'On task {task}.\\n\\tThe number of samples in the train dataset is ')\n",
        "    elif sel == 'pref_medical_terms': \n",
        "        print('sel', sel)\n",
        "        df_train['Text'] = sel_medical_terms(df_train['Text'])\n",
        "        df_test['Text'] = sel_medical_terms(df_test['Text'])\n",
        "        train_final_size = df_train['Text'].apply(lambda x: len(x)).sum()\n",
        "        test_final_size = df_test['Text'].apply(lambda x: len(x)).sum()\n",
        "        print(f'On task {task}.\\n\\tThe number of samples in the train dataset is ', len(df_train))\n",
        "    elif sel == 'r80':\n",
        "        print('sel', sel)\n",
        "        df_train['Text'] = random_cont_selection(df_train['Text'])\n",
        "        # df_test['Text'] = random_cont_selection(df_test['Text'])\n",
        "    elif sel == 'r100':\n",
        "        print('sel', sel)\n",
        "        df_train['Text'] = random_cont_selection(df_train['Text'], 100)\n",
        "        # df_test['Text'] = random_cont_selection(df_test['Text'])\n",
        "    elif sel == 'dev80':\n",
        "        print('sel', sel)\n",
        "        df_train['Text'] = recent_selection(df_train['Text'])\n",
        "        # df_test['Text'] = random_cont_selection(df_test['Text'])\n",
        "    return df_train, df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJsOBapiYXKH"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "class CustomTextDataset(Dataset):\n",
        "    def __init__(self, tokens_mask, labels):\n",
        "        self.tokens_mask = tokens_mask\n",
        "        self.labels = labels\n",
        "        self.size = 10\n",
        "        random.seed(42)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label = self.labels[idx]\n",
        "        data = self.tokens_mask[idx]\n",
        "        start = random.randint(0, data['tokens'].shape[0] - self.size)\n",
        "        data_short = {v: data[v][start: start + self.size] for v in data}\n",
        "        return [data_short, label]\n",
        "\n",
        "class CustomTextDatasetText(Dataset):\n",
        "    def __init__(self, tokens_mask, texts, labels):\n",
        "        self.tokens_mask = tokens_mask\n",
        "        self.labels = labels\n",
        "        self.texts = texts\n",
        "        self.size = 10\n",
        "        random.seed(42)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label = self.labels[idx]\n",
        "        data = self.tokens_mask[idx]\n",
        "        start = random.randint(0, data['tokens'].shape[0] - self.size)\n",
        "        data_short = {v: data[v][start: start + self.size] for v in data}\n",
        "        print(type(self.texts[idx]), self.texts[idx])\n",
        "        # print(type(self.texts[idx]), self.texts[idx])\n",
        "        texts = self.texts[idx][start: start + self.size]\n",
        "        # print(texts)\n",
        "        return [data_short, texts, label]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Aj00uIQYgOb",
        "outputId": "b30e8d99-460c-49a7-aeca-c6261958accc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "device = torch.device('cuda')\n",
        "print(device)\n",
        "source_folder = 'Data'\n",
        "destination_folder = 'Model'\n",
        "\n",
        "\n",
        "# Define the function for creating a weight dictionary.\n",
        "def create_weight_dict(labels):\n",
        "    unique_labels = np.unique(labels)\n",
        "    class_weights = class_weight.compute_class_weight('balanced', classes=unique_labels, y=labels)\n",
        "    return class_weights\n",
        "\n",
        "\n",
        "def get_loss(outputs, b_labels, vect_weights):\n",
        "    loss_fct = CrossEntropyLoss(weight=torch.tensor(vect_weights, dtype=torch.float32))\n",
        "    loss_fct.to(device)\n",
        "    loss = loss_fct(outputs[1].view(-1, 2), b_labels.view(-1))\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lW-wDuO_YkMm"
      },
      "outputs": [],
      "source": [
        "class ExpertGate(nn.Module):\n",
        "    def __init__(self, device, s, output_size=2):\n",
        "        super(ExpertGate, self).__init__()\n",
        "        self.device = device\n",
        "        self.hidden_size = s\n",
        "        self.rnn = nn.LSTM(input_size=self.hidden_size, hidden_size=100,\n",
        "                           num_layers=4, bidirectional=True)\n",
        "        self.sample_size = 10\n",
        "        self.fc_out3 = nn.Linear(6000, 1000)\n",
        "        self.fc_out2 = nn.Linear(1000, 100)\n",
        "        self.fc_out1 = nn.Linear(100 * self.sample_size, output_size)\n",
        "\n",
        "    def forward(self, bert_vectors):\n",
        "        outputs = []\n",
        "        # iterate in the batch through all sequences\n",
        "        for encoded in bert_vectors:\n",
        "            # encoded = self.bert(input_ids=token, attention_mask=mask)['last_hidden_state']\n",
        "            out, hiden = self.rnn(encoded)\n",
        "            out = self.fc_out3(out.view(self.sample_size, -1))\n",
        "            out = F.dropout(out, 0.5)\n",
        "            out = self.fc_out2(out)\n",
        "            out = F.dropout(out, 0.5)\n",
        "            out = self.fc_out1(out.view(-1))\n",
        "            out = torch.softmax(out, -1)\n",
        "            outputs.append(out.squeeze())\n",
        "        outputs = torch.stack(outputs)\n",
        "        return outputs\n",
        "\n",
        "class MoE(nn.Module):\n",
        "    def __init__(self, device, exps=3):\n",
        "        super(MoE, self).__init__()\n",
        "        pre_trained = 'neuralmind/bert-base-portuguese-cased'\n",
        "        self.bert = BertModel.from_pretrained(pre_trained)\n",
        "        self.exps = exps\n",
        "        self.device = device\n",
        "        self.nets = nn.ModuleList([\n",
        "          ExpertGate(device, self.bert.config.hidden_size) for _ in range(self.exps)\n",
        "        ])\n",
        "        self.gating = ExpertGate(device, self.bert.config.hidden_size, output_size=exps)\n",
        "    \n",
        "    def forward(self, atts, masks):\n",
        "        bert_out = []\n",
        "        for token, mask in zip(atts, masks):\n",
        "            # print(1)\n",
        "            bert_vectors = self.bert(input_ids=token, attention_mask=mask)['last_hidden_state']\n",
        "            bert_out.append(bert_vectors)\n",
        "        # print(2)\n",
        "        weights_sof = self.gating(bert_out)\n",
        "        # print(3)\n",
        "        preds = []\n",
        "        for n in self.nets:\n",
        "            # print(4)\n",
        "            preds.append(n(bert_out))\n",
        "        # print(5)\n",
        "        return (torch.stack(preds) * weights_sof.T[..., None]).sum(0)\n",
        "\n",
        "class MoEBR(nn.Module):\n",
        "    def __init__(self, device, exps=3):\n",
        "        super(MoEBR, self).__init__()\n",
        "        pre_trained = 'pablocosta/bertweet-br-base-uncased'\n",
        "        self.bert = BertModel.from_pretrained(pre_trained)\n",
        "        self.exps = exps\n",
        "        self.device = device\n",
        "        self.nets = nn.ModuleList([\n",
        "          ExpertGate(device, self.bert.config.hidden_size) for _ in range(self.exps)\n",
        "        ])\n",
        "        self.gating = ExpertGate(device, self.bert.config.hidden_size, output_size=exps)\n",
        "    \n",
        "    def forward(self, atts, masks):\n",
        "        bert_out = []\n",
        "        for token, mask in zip(atts, masks):\n",
        "            # print(1)\n",
        "            bert_vectors = self.bert(input_ids=token, attention_mask=mask)['last_hidden_state']\n",
        "            bert_out.append(bert_vectors)\n",
        "        # print(2)\n",
        "        weights_sof = self.gating(bert_out)\n",
        "        # print(3)\n",
        "        preds = []\n",
        "        for n in self.nets:\n",
        "            # print(4)\n",
        "            preds.append(n(bert_out))\n",
        "        # print(5)\n",
        "        return (torch.stack(preds) * weights_sof.T[..., None]).sum(0)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nj8TSDRIYoG0"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def get_tokens_mask_dates_split(X=None, y=None, tokenizer=None, type_data=None, task=None, sel=None, ml=30):\n",
        "    path = f'/content/drive/MyDrive/doutorado/diag_trat_saving/{type_data}_{sel}_{task}_processed.pkl'\n",
        "\n",
        "    if os.path.isfile(path):\n",
        "        print('load', path)\n",
        "        # 0/0\n",
        "        X_processed, y = pickle.load(open(path, 'rb'))\n",
        "    else:\n",
        "        print('Prepare')\n",
        "        X_processed = []\n",
        "        for user_posts in tqdm(X):\n",
        "            # print(tokenizer)\n",
        "            user_posts = user_posts[-1500:]\n",
        "            tokenized_texts = tokenizer.batch_encode_plus(user_posts, max_length=ml, padding='max_length', truncation=True)\n",
        "            tokens_tensor = torch.tensor(tokenized_texts['input_ids'])\n",
        "            segments_tensors = torch.tensor(tokenized_texts['attention_mask'])\n",
        "            X_processed.append(\n",
        "                {'tokens': tokens_tensor,\n",
        "                 'mask': segments_tensors,\n",
        "                 }\n",
        "            )\n",
        "        pickle.dump([X_processed, y], open(path, 'wb'))\n",
        "    return X_processed, y\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMcuAGe0d_sr"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(save_path, model, valid_loss):\n",
        "    if save_path == None:\n",
        "        return\n",
        "\n",
        "    state_dict = {'model_state_dict': model.state_dict(),\n",
        "                  'valid_loss': valid_loss}\n",
        "\n",
        "    torch.save(state_dict, save_path)\n",
        "    print(f'Model saved to ==> {save_path}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-JOmf_Do5kN"
      },
      "outputs": [],
      "source": [
        "def get_dataloader(X_, y_, shuffle):\n",
        "    batch_size = 16\n",
        "    TD_ = CustomTextDataset(X_, y_)\n",
        "    return DataLoader(TD_, batch_size=batch_size, shuffle=shuffle, collate_fn=(lambda x: x))\n",
        "\n",
        "def get_dataloader_text(X_, X_raw, y_, shuffle):\n",
        "    batch_size = 16\n",
        "    TD_ = CustomTextDatasetText(X_, X_raw, y_)\n",
        "    return DataLoader(TD_, batch_size=batch_size, shuffle=shuffle, collate_fn=(lambda x: x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LX6fz86mCYib"
      },
      "outputs": [],
      "source": [
        "def load_checkpoint(load_path, model):\n",
        "    if load_path == None:\n",
        "        return\n",
        "\n",
        "    state_dict = torch.load(load_path, map_location=device)\n",
        "    print(f'Model loaded from <== {load_path}')\n",
        "\n",
        "    model.load_state_dict(state_dict['model_state_dict'])\n",
        "    return state_dict['valid_loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZeiTr_forDO"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "def run_train(task, sel, model_name):\n",
        "    print(task, sel, model_name)\n",
        "    try:\n",
        "        print('Load')\n",
        "        # 1/0\n",
        "        X_train, y_train = get_tokens_mask_dates_split(None, None, None, 'train', task, sel)\n",
        "        X_test, y_test = get_tokens_mask_dates_split(None, None, None, 'test', task, sel)    \n",
        "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "    except:\n",
        "        print('Create')\n",
        "        df_train, df_test = load_convert(task, sel)\n",
        "        print(len(df_train), len(df_test))   \n",
        "        # return df_train, df_test\n",
        "        # tokenizer = BertTokenizerFast.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
        "        tokenizer = BertTokenizerFast.from_pretrained('pablocosta/bertweet-br-base-uncased')\n",
        "        X_train, y_train = get_tokens_mask_dates_split(df_train['Text'].tolist(), df_train['label'].tolist(), tokenizer, 'train', task, sel)\n",
        "        X_test, y_test = get_tokens_mask_dates_split(df_test['Text'].tolist(), df_test['label'].tolist(), tokenizer, 'test', task, sel)    \n",
        "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "    dataloader_train = get_dataloader(X_train, y_train, True)\n",
        "    dataloader_val = get_dataloader(X_val, y_val, True)\n",
        "    dataloader_test = get_dataloader(X_test, y_test, False)\n",
        "\n",
        "    device = 'cuda'\n",
        "    if model_name == 'moe':\n",
        "        model = MoE(device)\n",
        "    elif model_name == 'moe_br':\n",
        "        model = MoEBR(device)\n",
        "    else:\n",
        "        raise Exception('Model not defined')\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    print('*' * 20)\n",
        "    \n",
        "    lr = 1e-5\n",
        "    optimizer = AdamW(model.parameters(), lr=lr)\n",
        "\n",
        "    train_loss_set = []\n",
        "    epochs = 50\n",
        "    file_path = f'/content/drive/MyDrive/doutorado/diag_trat_saving/{sel}/'\n",
        "    vect_weights = create_weight_dict(y_train)\n",
        "    print(vect_weights)\n",
        "    loss_fct = CrossEntropyLoss(weight=torch.tensor(vect_weights, dtype=torch.float32), reduction='mean')\n",
        "    loss_fct.to(device)\n",
        "    for epoch in range(epochs):\n",
        "        print(f'Epoch {epoch}')\n",
        "        model.train()\n",
        "        pred, true_label = [], []\n",
        "        print(len(dataloader_train))\n",
        "        for i, batch in enumerate(dataloader_train):\n",
        "            if i % 100 == 0:\n",
        "                print(datetime.fromtimestamp(time.time()), i, train_loss_set[-1] if len(train_loss_set) else 0)\n",
        "            atts = torch.stack([aa[0]['tokens'] for aa in batch]).to(device)\n",
        "            masks = torch.stack([aa[0]['mask'] for aa in batch]).to(device)\n",
        "            outputs = model(atts, masks)\n",
        "            loss = loss_fct(outputs, torch.tensor([b[1] for b in batch]).to(device))\n",
        "            # output = loss(torch.argmax(outputs[1], dim=1).add_(-1), b_labels.add_(-1))\n",
        "            train_loss_set.append(loss.item())\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "            # Update parameters and take a step using the computed gradient\n",
        "            optimizer.step()\n",
        "            # scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            pred = pred + outputs.cpu().argmax(1).tolist()\n",
        "            true_label = true_label + [b[1] for b in batch]\n",
        "            gc.collect()\n",
        "            torch.cuda.empty_cache()\n",
        "        print('Results')\n",
        "        print(classification_report(true_label, pred))\n",
        "        # continue\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            # validation loop\n",
        "            pred, real = [], []\n",
        "            for j, batch in enumerate(dataloader_val):\n",
        "                atts = torch.stack([aa[0]['tokens'] for aa in batch]).to(device)\n",
        "                masks = torch.stack([aa[0]['mask'] for aa in batch]).to(device)\n",
        "                if model_name == 'ens':\n",
        "                    outputs, model_outputs = model(atts, masks)\n",
        "                else:\n",
        "                    outputs = model(atts, masks)\n",
        "\n",
        "                pred = pred + outputs.cpu().argmax(1).tolist()\n",
        "                real = real + [b[1] for b in batch]\n",
        "            print(classification_report(real, pred))\n",
        "            save_checkpoint(file_path + '/' + f'model-{model_name}-{task}-sel-{sel}-epoch{epoch}.pt', model, 0)\n",
        "        model.train()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e86c88a4a2a04972b9a604f7f0b01fae",
            "3fb2eb8d5f7949dd9a3f1e460708c4cf",
            "6eefa2cc98864ae38f35d62ef959692b",
            "a0c7c297b63a4794a9970e0c94fd72dc",
            "ce0b346f292b4b51bb90fe5977a97e4e",
            "7bee93f89c794ced8bf564e14372f448",
            "067995218ac6415b9c56ce11237f69f4",
            "c1d1147c61d3460790d639919d55153a",
            "0689ee863fa74fd0a38b1ff85d8794ae",
            "5096569d0b8c49c0b2f63079191dbb4f",
            "516cfca1c8c34ffdbe9984dd074d68f4",
            "b8dbd476b52d421a9c848676dfda2ee7",
            "94e6e974927b4a749e5d84f2f94fa011",
            "b23f7718273c42b4918630a61c15beb8",
            "2ddf361a2eec49e893963ab73101a884",
            "f10bdf4dd40543028ecf26d34c2597d3",
            "0b63e4edeff643a7abe08fb7c21654ca",
            "4a258085d9a04321bc7b984f76cf36ec",
            "beb7d3ed5a584afb87e93baf3545c569",
            "bc90d0167cc7486882f01c3e3285d174",
            "8081a1975dc34de7b4b050ebff5d8988",
            "fd15e70a88444a9f8a5d9fcdf2be4bdd"
          ]
        },
        "id": "fA2TgLlydyjy",
        "outputId": "91d40e8e-2883-45ab-d694-16d3a6f5179d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A all_br bert_twitter\n",
            "Load\n",
            "load /content/drive/MyDrive/doutorado/diag_trat_saving/train_all_br_A_processed.pkl\n",
            "load /content/drive/MyDrive/doutorado/diag_trat_saving/test_all_br_A_processed.pkl\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e86c88a4a2a04972b9a604f7f0b01fae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/384 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b8dbd476b52d421a9c848676dfda2ee7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/518M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at pablocosta/bertweet-br-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "********************\n",
            "[0.57315843 3.91724138]\n",
            "Epoch 0\n",
            "710\n",
            "2022-08-26 15:54:00.119235 0 0\n",
            "2022-08-26 15:55:59.523579 100 0.6958425045013428\n",
            "2022-08-26 15:57:58.077085 200 0.7556463479995728\n",
            "2022-08-26 15:59:56.677386 300 0.643033504486084\n",
            "2022-08-26 16:01:55.224315 400 0.6591290831565857\n",
            "2022-08-26 16:03:53.691870 500 0.6274153590202332\n",
            "2022-08-26 16:05:52.052942 600 0.7589823603630066\n",
            "2022-08-26 16:07:50.383814 700 0.6568059325218201\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.83      0.86      9910\n",
            "           1       0.17      0.23      0.19      1450\n",
            "\n",
            "    accuracy                           0.76     11360\n",
            "   macro avg       0.52      0.53      0.53     11360\n",
            "weighted avg       0.79      0.76      0.77     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.85      0.88      2515\n",
            "           1       0.24      0.36      0.29       325\n",
            "\n",
            "    accuracy                           0.79      2840\n",
            "   macro avg       0.58      0.61      0.58      2840\n",
            "weighted avg       0.83      0.79      0.81      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch0.pt\n",
            "Epoch 1\n",
            "710\n",
            "2022-08-26 16:08:55.334383 0 0.8056344985961914\n",
            "2022-08-26 16:10:54.430501 100 0.52032071352005\n",
            "2022-08-26 16:12:53.069656 200 0.5945544838905334\n",
            "2022-08-26 16:14:51.785622 300 0.5587276816368103\n",
            "2022-08-26 16:16:50.506842 400 0.5428759455680847\n",
            "2022-08-26 16:18:49.175007 500 0.46057456731796265\n",
            "2022-08-26 16:20:48.044542 600 0.6130738854408264\n",
            "2022-08-26 16:22:46.730635 700 0.5961353182792664\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.68      0.78      9910\n",
            "           1       0.21      0.57      0.30      1450\n",
            "\n",
            "    accuracy                           0.66     11360\n",
            "   macro avg       0.56      0.62      0.54     11360\n",
            "weighted avg       0.82      0.66      0.72     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.58      0.72      2515\n",
            "           1       0.18      0.72      0.29       325\n",
            "\n",
            "    accuracy                           0.59      2840\n",
            "   macro avg       0.56      0.65      0.50      2840\n",
            "weighted avg       0.85      0.59      0.67      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch1.pt\n",
            "Epoch 2\n",
            "710\n",
            "2022-08-26 16:23:49.039884 0 0.5847334265708923\n",
            "2022-08-26 16:25:48.108011 100 0.5731099247932434\n",
            "2022-08-26 16:27:46.836340 200 0.6228086352348328\n",
            "2022-08-26 16:29:45.424378 300 0.6183244585990906\n",
            "2022-08-26 16:31:44.220469 400 0.8095054030418396\n",
            "2022-08-26 16:33:42.862392 500 0.804530918598175\n",
            "2022-08-26 16:35:41.523947 600 0.6143467426300049\n",
            "2022-08-26 16:37:40.189266 700 0.609677791595459\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.69      0.79      9910\n",
            "           1       0.21      0.56      0.30      1450\n",
            "\n",
            "    accuracy                           0.67     11360\n",
            "   macro avg       0.56      0.62      0.54     11360\n",
            "weighted avg       0.82      0.67      0.72     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.74      0.82      2515\n",
            "           1       0.21      0.54      0.30       325\n",
            "\n",
            "    accuracy                           0.72      2840\n",
            "   macro avg       0.57      0.64      0.56      2840\n",
            "weighted avg       0.84      0.72      0.76      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch2.pt\n",
            "Epoch 3\n",
            "710\n",
            "2022-08-26 16:38:38.256923 0 0.5114873051643372\n",
            "2022-08-26 16:40:37.532191 100 0.7151232957839966\n",
            "2022-08-26 16:42:36.233100 200 0.6215528249740601\n",
            "2022-08-26 16:44:34.869130 300 0.72055983543396\n",
            "2022-08-26 16:46:33.640561 400 0.6268771290779114\n",
            "2022-08-26 16:48:32.349760 500 0.6126528382301331\n",
            "2022-08-26 16:50:31.033035 600 0.5113350749015808\n",
            "2022-08-26 16:52:29.789943 700 0.5534540414810181\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.69      0.79      9910\n",
            "           1       0.22      0.59      0.32      1450\n",
            "\n",
            "    accuracy                           0.68     11360\n",
            "   macro avg       0.57      0.64      0.55     11360\n",
            "weighted avg       0.83      0.68      0.73     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.92      0.91      2515\n",
            "           1       0.31      0.27      0.29       325\n",
            "\n",
            "    accuracy                           0.85      2840\n",
            "   macro avg       0.61      0.60      0.60      2840\n",
            "weighted avg       0.84      0.85      0.84      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch3.pt\n",
            "Epoch 4\n",
            "710\n",
            "2022-08-26 16:53:30.996704 0 0.7103244066238403\n",
            "2022-08-26 16:55:30.084365 100 0.6714614629745483\n",
            "2022-08-26 16:57:28.861001 200 0.5395439267158508\n",
            "2022-08-26 16:59:27.611316 300 0.6670476794242859\n",
            "2022-08-26 17:01:26.298195 400 0.7586560249328613\n",
            "2022-08-26 17:03:24.943784 500 0.4559415280818939\n",
            "2022-08-26 17:05:23.845964 600 0.6587575078010559\n",
            "2022-08-26 17:07:22.689210 700 0.6679799556732178\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.70      0.79      9910\n",
            "           1       0.22      0.58      0.32      1450\n",
            "\n",
            "    accuracy                           0.68     11360\n",
            "   macro avg       0.57      0.64      0.56     11360\n",
            "weighted avg       0.83      0.68      0.73     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.70      0.80      2515\n",
            "           1       0.20      0.60      0.30       325\n",
            "\n",
            "    accuracy                           0.69      2840\n",
            "   macro avg       0.57      0.65      0.55      2840\n",
            "weighted avg       0.85      0.69      0.74      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch4.pt\n",
            "Epoch 5\n",
            "710\n",
            "2022-08-26 17:08:29.831216 0 0.6481137275695801\n",
            "2022-08-26 17:10:29.645807 100 0.6074826717376709\n",
            "2022-08-26 17:12:28.946194 200 0.5101658701896667\n",
            "2022-08-26 17:14:28.725964 300 0.560896098613739\n",
            "2022-08-26 17:16:27.978331 400 0.6241127252578735\n",
            "2022-08-26 17:18:27.999873 500 0.6013172268867493\n",
            "2022-08-26 17:20:27.019504 600 0.5910022854804993\n",
            "2022-08-26 17:22:26.058017 700 0.5846097469329834\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.69      0.79      9910\n",
            "           1       0.22      0.60      0.32      1450\n",
            "\n",
            "    accuracy                           0.68     11360\n",
            "   macro avg       0.57      0.64      0.55     11360\n",
            "weighted avg       0.83      0.68      0.73     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.64      0.76      2515\n",
            "           1       0.19      0.67      0.30       325\n",
            "\n",
            "    accuracy                           0.64      2840\n",
            "   macro avg       0.56      0.65      0.53      2840\n",
            "weighted avg       0.85      0.64      0.71      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch5.pt\n",
            "Epoch 6\n",
            "710\n",
            "2022-08-26 17:23:30.239870 0 0.6812806725502014\n",
            "2022-08-26 17:25:29.547779 100 0.8140761256217957\n",
            "2022-08-26 17:27:28.476165 200 0.6362891793251038\n",
            "2022-08-26 17:29:27.512699 300 0.6518210768699646\n",
            "2022-08-26 17:31:26.426116 400 0.5944600105285645\n",
            "2022-08-26 17:33:25.682150 500 0.5779643654823303\n",
            "2022-08-26 17:35:24.564150 600 0.620661735534668\n",
            "2022-08-26 17:37:24.164767 700 0.730424702167511\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.70      0.80      9910\n",
            "           1       0.22      0.57      0.32      1450\n",
            "\n",
            "    accuracy                           0.69     11360\n",
            "   macro avg       0.57      0.64      0.56     11360\n",
            "weighted avg       0.83      0.69      0.74     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.61      0.74      2515\n",
            "           1       0.19      0.71      0.30       325\n",
            "\n",
            "    accuracy                           0.62      2840\n",
            "   macro avg       0.57      0.66      0.52      2840\n",
            "weighted avg       0.86      0.62      0.69      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch6.pt\n",
            "Epoch 7\n",
            "710\n",
            "2022-08-26 17:38:29.960123 0 0.7723620533943176\n",
            "2022-08-26 17:40:29.538994 100 0.8086342811584473\n",
            "2022-08-26 17:42:28.492542 200 0.4955001771450043\n",
            "2022-08-26 17:44:27.729849 300 0.7147040367126465\n",
            "2022-08-26 17:46:26.683753 400 0.562626838684082\n",
            "2022-08-26 17:48:26.096187 500 0.669933021068573\n",
            "2022-08-26 17:50:24.892178 600 0.5637134313583374\n",
            "2022-08-26 17:52:23.780082 700 0.8680242300033569\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.70      0.80      9910\n",
            "           1       0.23      0.63      0.34      1450\n",
            "\n",
            "    accuracy                           0.69     11360\n",
            "   macro avg       0.58      0.67      0.57     11360\n",
            "weighted avg       0.84      0.69      0.74     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.61      0.74      2515\n",
            "           1       0.19      0.70      0.30       325\n",
            "\n",
            "    accuracy                           0.62      2840\n",
            "   macro avg       0.56      0.65      0.52      2840\n",
            "weighted avg       0.85      0.62      0.69      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch7.pt\n",
            "Epoch 8\n",
            "710\n",
            "2022-08-26 17:53:25.884056 0 0.533584713935852\n",
            "2022-08-26 17:55:25.126614 100 0.6002469062805176\n",
            "2022-08-26 17:57:23.968080 200 0.8567111492156982\n",
            "2022-08-26 17:59:23.009704 300 0.47965577244758606\n",
            "2022-08-26 18:01:22.279181 400 0.8189458250999451\n",
            "2022-08-26 18:03:21.661982 500 0.6494665741920471\n",
            "2022-08-26 18:05:20.557104 600 0.6898943185806274\n",
            "2022-08-26 18:07:19.338312 700 0.7337305545806885\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.71      0.80      9910\n",
            "           1       0.23      0.59      0.33      1450\n",
            "\n",
            "    accuracy                           0.69     11360\n",
            "   macro avg       0.57      0.65      0.57     11360\n",
            "weighted avg       0.83      0.69      0.74     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.78      0.85      2515\n",
            "           1       0.23      0.51      0.32       325\n",
            "\n",
            "    accuracy                           0.75      2840\n",
            "   macro avg       0.58      0.64      0.58      2840\n",
            "weighted avg       0.84      0.75      0.79      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch8.pt\n",
            "Epoch 9\n",
            "710\n",
            "2022-08-26 18:08:23.446351 0 0.7023893594741821\n",
            "2022-08-26 18:10:22.907106 100 0.7090020775794983\n",
            "2022-08-26 18:12:21.937350 200 0.6935332417488098\n",
            "2022-08-26 18:14:20.765461 300 0.6325669884681702\n",
            "2022-08-26 18:16:19.619841 400 0.8666192889213562\n",
            "2022-08-26 18:18:18.484858 500 0.7926367521286011\n",
            "2022-08-26 18:20:17.432824 600 0.4900999665260315\n",
            "2022-08-26 18:22:16.270671 700 0.837131142616272\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.70      0.80      9910\n",
            "           1       0.23      0.60      0.33      1450\n",
            "\n",
            "    accuracy                           0.69     11360\n",
            "   macro avg       0.58      0.65      0.56     11360\n",
            "weighted avg       0.83      0.69      0.74     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.57      0.71      2515\n",
            "           1       0.18      0.72      0.29       325\n",
            "\n",
            "    accuracy                           0.59      2840\n",
            "   macro avg       0.56      0.65      0.50      2840\n",
            "weighted avg       0.85      0.59      0.66      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch9.pt\n",
            "Epoch 10\n",
            "710\n",
            "2022-08-26 18:23:19.125222 0 0.7109907269477844\n",
            "2022-08-26 18:25:18.387274 100 0.5699796676635742\n",
            "2022-08-26 18:27:17.284412 200 0.5199689865112305\n",
            "2022-08-26 18:29:16.080539 300 0.6587709784507751\n",
            "2022-08-26 18:31:14.952564 400 0.9036003351211548\n",
            "2022-08-26 18:33:13.908024 500 0.6909859776496887\n",
            "2022-08-26 18:35:12.869838 600 0.7252852320671082\n",
            "2022-08-26 18:37:11.619705 700 0.43353384733200073\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.72      0.81      9910\n",
            "           1       0.24      0.59      0.34      1450\n",
            "\n",
            "    accuracy                           0.70     11360\n",
            "   macro avg       0.58      0.66      0.57     11360\n",
            "weighted avg       0.84      0.70      0.75     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.71      0.80      2515\n",
            "           1       0.21      0.60      0.31       325\n",
            "\n",
            "    accuracy                           0.69      2840\n",
            "   macro avg       0.57      0.65      0.56      2840\n",
            "weighted avg       0.85      0.69      0.75      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch10.pt\n",
            "Epoch 11\n",
            "710\n",
            "2022-08-26 18:38:03.800298 0 0.6012909412384033\n",
            "2022-08-26 18:40:03.232120 100 0.4984411895275116\n",
            "2022-08-26 18:42:02.089911 200 0.5087872743606567\n",
            "2022-08-26 18:44:00.940451 300 0.4783976674079895\n",
            "2022-08-26 18:45:59.857834 400 0.7553210854530334\n",
            "2022-08-26 18:47:58.688907 500 0.5705503821372986\n",
            "2022-08-26 18:49:57.738452 600 0.679018497467041\n",
            "2022-08-26 18:51:56.920122 700 0.604250967502594\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.71      0.80      9910\n",
            "           1       0.23      0.59      0.33      1450\n",
            "\n",
            "    accuracy                           0.69     11360\n",
            "   macro avg       0.58      0.65      0.57     11360\n",
            "weighted avg       0.83      0.69      0.74     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.59      0.73      2515\n",
            "           1       0.19      0.75      0.31       325\n",
            "\n",
            "    accuracy                           0.61      2840\n",
            "   macro avg       0.57      0.67      0.52      2840\n",
            "weighted avg       0.86      0.61      0.68      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch11.pt\n",
            "Epoch 12\n",
            "710\n",
            "2022-08-26 18:52:49.205007 0 0.5825232267379761\n",
            "2022-08-26 18:54:48.562891 100 0.6243934035301208\n",
            "2022-08-26 18:56:47.933856 200 0.6437674164772034\n",
            "2022-08-26 18:58:46.896405 300 0.5356878042221069\n",
            "2022-08-26 19:00:45.916813 400 0.5295970439910889\n",
            "2022-08-26 19:02:44.795783 500 0.5814682841300964\n",
            "2022-08-26 19:04:43.725300 600 0.6451783776283264\n",
            "2022-08-26 19:06:42.556082 700 0.6614093780517578\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.70      0.80      9910\n",
            "           1       0.23      0.61      0.33      1450\n",
            "\n",
            "    accuracy                           0.69     11360\n",
            "   macro avg       0.58      0.66      0.56     11360\n",
            "weighted avg       0.84      0.69      0.74     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.66      0.78      2515\n",
            "           1       0.21      0.69      0.32       325\n",
            "\n",
            "    accuracy                           0.66      2840\n",
            "   macro avg       0.58      0.68      0.55      2840\n",
            "weighted avg       0.86      0.66      0.72      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch12.pt\n",
            "Epoch 13\n",
            "710\n",
            "2022-08-26 19:07:35.657937 0 0.5684567093849182\n",
            "2022-08-26 19:09:34.926159 100 0.5151609182357788\n",
            "2022-08-26 19:11:33.902625 200 0.6830127239227295\n",
            "2022-08-26 19:13:32.785716 300 0.4922860562801361\n",
            "2022-08-26 19:15:31.691500 400 0.4951408803462982\n",
            "2022-08-26 19:17:30.793698 500 0.5999212861061096\n",
            "2022-08-26 19:19:29.731781 600 0.7362403273582458\n",
            "2022-08-26 19:21:28.655803 700 0.6498647332191467\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.72      0.81      9910\n",
            "           1       0.24      0.60      0.34      1450\n",
            "\n",
            "    accuracy                           0.71     11360\n",
            "   macro avg       0.58      0.66      0.58     11360\n",
            "weighted avg       0.84      0.71      0.75     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.76      0.84      2515\n",
            "           1       0.21      0.49      0.30       325\n",
            "\n",
            "    accuracy                           0.73      2840\n",
            "   macro avg       0.57      0.63      0.57      2840\n",
            "weighted avg       0.84      0.73      0.77      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch13.pt\n",
            "Epoch 14\n",
            "710\n",
            "2022-08-26 19:22:21.516726 0 0.6151519417762756\n",
            "2022-08-26 19:24:20.725578 100 0.5690856575965881\n",
            "2022-08-26 19:26:19.661564 200 0.4126201868057251\n",
            "2022-08-26 19:28:18.400970 300 0.8408163189888\n",
            "2022-08-26 19:30:17.166565 400 0.505438506603241\n",
            "2022-08-26 19:32:16.001842 500 0.6550679802894592\n",
            "2022-08-26 19:34:14.772469 600 0.6227776408195496\n",
            "2022-08-26 19:36:13.673401 700 0.6262728571891785\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.73      0.81      9910\n",
            "           1       0.24      0.60      0.34      1450\n",
            "\n",
            "    accuracy                           0.71     11360\n",
            "   macro avg       0.58      0.66      0.58     11360\n",
            "weighted avg       0.84      0.71      0.75     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.64      0.76      2515\n",
            "           1       0.18      0.63      0.29       325\n",
            "\n",
            "    accuracy                           0.64      2840\n",
            "   macro avg       0.56      0.64      0.52      2840\n",
            "weighted avg       0.85      0.64      0.71      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch14.pt\n",
            "Epoch 15\n",
            "710\n",
            "2022-08-26 19:37:05.972457 0 0.5247465372085571\n",
            "2022-08-26 19:39:05.294340 100 0.7223390936851501\n",
            "2022-08-26 19:41:04.136139 200 0.5432847142219543\n",
            "2022-08-26 19:43:02.991884 300 0.41501161456108093\n",
            "2022-08-26 19:45:02.179968 400 0.40286487340927124\n",
            "2022-08-26 19:47:01.546453 500 0.7401059865951538\n",
            "2022-08-26 19:49:01.452069 600 0.41919177770614624\n",
            "2022-08-26 19:51:00.668171 700 0.7201884388923645\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.74      0.82      9910\n",
            "           1       0.25      0.58      0.35      1450\n",
            "\n",
            "    accuracy                           0.72     11360\n",
            "   macro avg       0.59      0.66      0.58     11360\n",
            "weighted avg       0.84      0.72      0.76     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.81      0.86      2515\n",
            "           1       0.24      0.47      0.32       325\n",
            "\n",
            "    accuracy                           0.77      2840\n",
            "   macro avg       0.58      0.64      0.59      2840\n",
            "weighted avg       0.84      0.77      0.80      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch15.pt\n",
            "Epoch 16\n",
            "710\n",
            "2022-08-26 19:51:53.017694 0 0.7659717202186584\n",
            "2022-08-26 19:53:52.711903 100 0.5803956985473633\n",
            "2022-08-26 19:55:51.794518 200 0.504708468914032\n",
            "2022-08-26 19:57:50.822987 300 0.640791118144989\n",
            "2022-08-26 19:59:49.946212 400 0.4986205995082855\n",
            "2022-08-26 20:01:49.013755 500 0.747029721736908\n",
            "2022-08-26 20:03:48.602488 600 0.6431820392608643\n",
            "2022-08-26 20:05:48.433436 700 0.534700870513916\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.72      0.81      9910\n",
            "           1       0.25      0.62      0.36      1450\n",
            "\n",
            "    accuracy                           0.71     11360\n",
            "   macro avg       0.59      0.67      0.58     11360\n",
            "weighted avg       0.84      0.71      0.76     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.49      0.65      2515\n",
            "           1       0.17      0.78      0.27       325\n",
            "\n",
            "    accuracy                           0.52      2840\n",
            "   macro avg       0.55      0.63      0.46      2840\n",
            "weighted avg       0.86      0.52      0.60      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch16.pt\n",
            "Epoch 17\n",
            "710\n",
            "2022-08-26 20:06:40.822223 0 0.6274129152297974\n",
            "2022-08-26 20:08:40.720085 100 0.5623590350151062\n",
            "2022-08-26 20:10:40.168566 200 0.6307292580604553\n",
            "2022-08-26 20:12:39.497187 300 0.6275535821914673\n",
            "2022-08-26 20:14:39.035403 400 0.6641992330551147\n",
            "2022-08-26 20:16:38.413485 500 0.6207026243209839\n",
            "2022-08-26 20:18:37.777902 600 0.5238858461380005\n",
            "2022-08-26 20:20:38.061133 700 0.6187804937362671\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.72      0.81      9910\n",
            "           1       0.24      0.60      0.34      1450\n",
            "\n",
            "    accuracy                           0.71     11360\n",
            "   macro avg       0.58      0.66      0.58     11360\n",
            "weighted avg       0.84      0.71      0.75     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.86      0.89      2515\n",
            "           1       0.27      0.40      0.32       325\n",
            "\n",
            "    accuracy                           0.80      2840\n",
            "   macro avg       0.59      0.63      0.60      2840\n",
            "weighted avg       0.84      0.80      0.82      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch17.pt\n",
            "Epoch 18\n",
            "710\n",
            "2022-08-26 20:21:30.494521 0 0.8807939291000366\n",
            "2022-08-26 20:23:30.368944 100 0.5946614146232605\n",
            "2022-08-26 20:25:29.568105 200 0.5118913054466248\n",
            "2022-08-26 20:27:28.743868 300 0.4977072775363922\n",
            "2022-08-26 20:29:28.269941 400 0.5092918276786804\n",
            "2022-08-26 20:31:27.827722 500 0.7249057292938232\n",
            "2022-08-26 20:33:27.248402 600 0.676186740398407\n",
            "2022-08-26 20:35:26.798226 700 0.555007815361023\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.72      0.81      9910\n",
            "           1       0.25      0.63      0.35      1450\n",
            "\n",
            "    accuracy                           0.71     11360\n",
            "   macro avg       0.59      0.67      0.58     11360\n",
            "weighted avg       0.84      0.71      0.75     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.83      0.87      2515\n",
            "           1       0.24      0.42      0.30       325\n",
            "\n",
            "    accuracy                           0.78      2840\n",
            "   macro avg       0.58      0.62      0.59      2840\n",
            "weighted avg       0.84      0.78      0.81      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch18.pt\n",
            "Epoch 19\n",
            "710\n",
            "2022-08-26 20:36:19.240232 0 0.677627682685852\n",
            "2022-08-26 20:38:19.298610 100 0.8315721154212952\n",
            "2022-08-26 20:40:18.940964 200 0.7125446796417236\n",
            "2022-08-26 20:42:18.332149 300 0.5431427955627441\n",
            "2022-08-26 20:44:17.970276 400 0.5864771604537964\n",
            "2022-08-26 20:46:17.604931 500 0.43481647968292236\n",
            "2022-08-26 20:48:17.327100 600 0.6103237271308899\n",
            "2022-08-26 20:50:16.791042 700 0.7478014826774597\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.72      0.81      9910\n",
            "           1       0.25      0.62      0.35      1450\n",
            "\n",
            "    accuracy                           0.71     11360\n",
            "   macro avg       0.59      0.67      0.58     11360\n",
            "weighted avg       0.84      0.71      0.75     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.83      0.87      2515\n",
            "           1       0.26      0.46      0.33       325\n",
            "\n",
            "    accuracy                           0.79      2840\n",
            "   macro avg       0.59      0.65      0.60      2840\n",
            "weighted avg       0.85      0.79      0.81      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch19.pt\n",
            "Epoch 20\n",
            "710\n",
            "2022-08-26 20:51:09.227977 0 0.7589008212089539\n",
            "2022-08-26 20:53:09.285946 100 0.6254897713661194\n",
            "2022-08-26 20:55:09.072909 200 0.49010753631591797\n",
            "2022-08-26 20:57:08.606063 300 0.6843277812004089\n",
            "2022-08-26 20:59:08.291055 400 0.6093924641609192\n",
            "2022-08-26 21:01:07.581307 500 0.384475976228714\n",
            "2022-08-26 21:03:07.211897 600 0.6105592846870422\n",
            "2022-08-26 21:05:07.030817 700 0.6011816263198853\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.74      0.82      9910\n",
            "           1       0.26      0.61      0.36      1450\n",
            "\n",
            "    accuracy                           0.72     11360\n",
            "   macro avg       0.59      0.67      0.59     11360\n",
            "weighted avg       0.84      0.72      0.76     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.84      0.88      2515\n",
            "           1       0.25      0.41      0.31       325\n",
            "\n",
            "    accuracy                           0.79      2840\n",
            "   macro avg       0.58      0.63      0.59      2840\n",
            "weighted avg       0.84      0.79      0.81      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch20.pt\n",
            "Epoch 21\n",
            "710\n",
            "2022-08-26 21:05:59.457246 0 0.5304397940635681\n",
            "2022-08-26 21:07:59.369488 100 0.8873251080513\n",
            "2022-08-26 21:09:58.886479 200 0.5008654594421387\n",
            "2022-08-26 21:11:58.429314 300 0.6645452380180359\n",
            "2022-08-26 21:13:58.151467 400 0.6056836247444153\n",
            "2022-08-26 21:15:57.948909 500 0.4789745807647705\n",
            "2022-08-26 21:17:57.456386 600 0.5672904253005981\n",
            "2022-08-26 21:19:57.102016 700 0.7995702624320984\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.75      0.83      9910\n",
            "           1       0.26      0.60      0.36      1450\n",
            "\n",
            "    accuracy                           0.73     11360\n",
            "   macro avg       0.59      0.68      0.60     11360\n",
            "weighted avg       0.84      0.73      0.77     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.76      0.83      2515\n",
            "           1       0.22      0.53      0.31       325\n",
            "\n",
            "    accuracy                           0.73      2840\n",
            "   macro avg       0.57      0.64      0.57      2840\n",
            "weighted avg       0.85      0.73      0.77      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch21.pt\n",
            "Epoch 22\n",
            "710\n",
            "2022-08-26 21:20:49.451842 0 0.49935635924339294\n",
            "2022-08-26 21:22:49.690615 100 0.4961366057395935\n",
            "2022-08-26 21:24:49.378562 200 0.5432780981063843\n",
            "2022-08-26 21:26:48.836271 300 0.7237772345542908\n",
            "2022-08-26 21:28:48.393397 400 0.5312245488166809\n",
            "2022-08-26 21:30:48.095832 500 0.4946334660053253\n",
            "2022-08-26 21:32:47.653549 600 0.6510998606681824\n",
            "2022-08-26 21:34:47.197136 700 0.7140029072761536\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.73      0.82      9910\n",
            "           1       0.25      0.63      0.36      1450\n",
            "\n",
            "    accuracy                           0.72     11360\n",
            "   macro avg       0.59      0.68      0.59     11360\n",
            "weighted avg       0.84      0.72      0.76     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.76      0.83      2515\n",
            "           1       0.22      0.54      0.31       325\n",
            "\n",
            "    accuracy                           0.73      2840\n",
            "   macro avg       0.57      0.65      0.57      2840\n",
            "weighted avg       0.85      0.73      0.77      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch22.pt\n",
            "Epoch 23\n",
            "710\n",
            "2022-08-26 21:35:39.931545 0 0.7231672406196594\n",
            "2022-08-26 21:37:40.938325 100 0.5848838090896606\n",
            "2022-08-26 21:39:40.642895 200 0.554974377155304\n",
            "2022-08-26 21:41:40.091063 300 0.5197487473487854\n",
            "2022-08-26 21:43:39.705798 400 0.6391928195953369\n",
            "2022-08-26 21:45:39.397824 500 0.4603859484195709\n",
            "2022-08-26 21:47:39.164688 600 0.40820884704589844\n",
            "2022-08-26 21:49:38.762455 700 0.5828202962875366\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.73      0.82      9910\n",
            "           1       0.26      0.64      0.37      1450\n",
            "\n",
            "    accuracy                           0.72     11360\n",
            "   macro avg       0.59      0.68      0.59     11360\n",
            "weighted avg       0.85      0.72      0.76     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.59      0.73      2515\n",
            "           1       0.19      0.74      0.30       325\n",
            "\n",
            "    accuracy                           0.61      2840\n",
            "   macro avg       0.57      0.66      0.51      2840\n",
            "weighted avg       0.86      0.61      0.68      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch23.pt\n",
            "Epoch 24\n",
            "710\n",
            "2022-08-26 21:50:31.234017 0 0.7190310955047607\n",
            "2022-08-26 21:52:31.305805 100 0.38085314631462097\n",
            "2022-08-26 21:54:31.007080 200 0.4076089560985565\n",
            "2022-08-26 21:56:30.704872 300 0.5374801158905029\n",
            "2022-08-26 21:58:30.272693 400 0.790726900100708\n",
            "2022-08-26 22:00:29.787276 500 0.800658106803894\n",
            "2022-08-26 22:02:29.382488 600 0.4164705276489258\n",
            "2022-08-26 22:04:29.204635 700 0.4428369998931885\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.73      0.82      9910\n",
            "           1       0.25      0.62      0.36      1450\n",
            "\n",
            "    accuracy                           0.72     11360\n",
            "   macro avg       0.59      0.68      0.59     11360\n",
            "weighted avg       0.84      0.72      0.76     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.62      0.74      2515\n",
            "           1       0.19      0.69      0.30       325\n",
            "\n",
            "    accuracy                           0.62      2840\n",
            "   macro avg       0.56      0.65      0.52      2840\n",
            "weighted avg       0.85      0.62      0.69      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch24.pt\n",
            "Epoch 25\n",
            "710\n",
            "2022-08-26 22:05:21.521307 0 0.730682373046875\n",
            "2022-08-26 22:07:21.451830 100 0.5663956999778748\n",
            "2022-08-26 22:09:21.113031 200 0.7592875361442566\n",
            "2022-08-26 22:11:20.769997 300 0.6466631889343262\n",
            "2022-08-26 22:13:20.608986 400 0.6026350855827332\n",
            "2022-08-26 22:15:20.308004 500 0.49513500928878784\n",
            "2022-08-26 22:17:20.008510 600 0.716349720954895\n",
            "2022-08-26 22:19:19.978296 700 0.4777625501155853\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.74      0.83      9910\n",
            "           1       0.27      0.63      0.38      1450\n",
            "\n",
            "    accuracy                           0.73     11360\n",
            "   macro avg       0.60      0.69      0.60     11360\n",
            "weighted avg       0.85      0.73      0.77     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.81      0.86      2515\n",
            "           1       0.23      0.46      0.31       325\n",
            "\n",
            "    accuracy                           0.77      2840\n",
            "   macro avg       0.58      0.63      0.59      2840\n",
            "weighted avg       0.84      0.77      0.80      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch25.pt\n",
            "Epoch 26\n",
            "710\n",
            "2022-08-26 22:20:12.538986 0 0.527962863445282\n",
            "2022-08-26 22:22:13.163261 100 0.9384377002716064\n",
            "2022-08-26 22:24:12.710263 200 0.6593066453933716\n",
            "2022-08-26 22:26:11.951743 300 0.4530392289161682\n",
            "2022-08-26 22:28:11.154187 400 0.5169371366500854\n",
            "2022-08-26 22:30:10.453432 500 0.5860017538070679\n",
            "2022-08-26 22:32:09.668837 600 0.5664379000663757\n",
            "2022-08-26 22:34:08.882305 700 0.576973021030426\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.74      0.82      9910\n",
            "           1       0.26      0.63      0.37      1450\n",
            "\n",
            "    accuracy                           0.72     11360\n",
            "   macro avg       0.60      0.68      0.60     11360\n",
            "weighted avg       0.85      0.72      0.76     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.76      0.83      2515\n",
            "           1       0.21      0.50      0.30       325\n",
            "\n",
            "    accuracy                           0.73      2840\n",
            "   macro avg       0.57      0.63      0.57      2840\n",
            "weighted avg       0.84      0.73      0.77      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch26.pt\n",
            "Epoch 27\n",
            "710\n",
            "2022-08-26 22:35:01.176743 0 0.5498912334442139\n",
            "2022-08-26 22:37:01.397166 100 0.43900150060653687\n",
            "2022-08-26 22:39:01.348622 200 0.6210150122642517\n",
            "2022-08-26 22:41:00.706809 300 0.8019188642501831\n",
            "2022-08-26 22:43:00.495132 400 0.4906073808670044\n",
            "2022-08-26 22:45:00.808154 500 0.6703511476516724\n",
            "2022-08-26 22:47:00.359957 600 0.38671696186065674\n",
            "2022-08-26 22:48:59.577948 700 0.5395737290382385\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.73      0.82      9910\n",
            "           1       0.25      0.62      0.36      1450\n",
            "\n",
            "    accuracy                           0.72     11360\n",
            "   macro avg       0.59      0.68      0.59     11360\n",
            "weighted avg       0.84      0.72      0.76     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.73      0.82      2515\n",
            "           1       0.21      0.55      0.30       325\n",
            "\n",
            "    accuracy                           0.71      2840\n",
            "   macro avg       0.57      0.64      0.56      2840\n",
            "weighted avg       0.84      0.71      0.76      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch27.pt\n",
            "Epoch 28\n",
            "710\n",
            "2022-08-26 22:49:51.944036 0 0.609838604927063\n",
            "2022-08-26 22:51:52.317010 100 0.49216118454933167\n",
            "2022-08-26 22:53:51.532969 200 0.6642788648605347\n",
            "2022-08-26 22:55:50.813848 300 0.7783568501472473\n",
            "2022-08-26 22:57:50.004768 400 0.830375075340271\n",
            "2022-08-26 22:59:49.238265 500 0.6222895383834839\n",
            "2022-08-26 23:01:48.514733 600 0.5026259422302246\n",
            "2022-08-26 23:03:47.865848 700 0.7814233303070068\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.75      0.83      9910\n",
            "           1       0.27      0.62      0.37      1450\n",
            "\n",
            "    accuracy                           0.73     11360\n",
            "   macro avg       0.60      0.68      0.60     11360\n",
            "weighted avg       0.85      0.73      0.77     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.74      0.82      2515\n",
            "           1       0.22      0.57      0.32       325\n",
            "\n",
            "    accuracy                           0.72      2840\n",
            "   macro avg       0.57      0.65      0.57      2840\n",
            "weighted avg       0.85      0.72      0.76      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch28.pt\n",
            "Epoch 29\n",
            "710\n",
            "2022-08-26 23:04:40.319803 0 0.4872494339942932\n",
            "2022-08-26 23:06:40.140338 100 0.5396751165390015\n",
            "2022-08-26 23:08:39.310846 200 0.6262732148170471\n",
            "2022-08-26 23:10:38.423103 300 0.45231667160987854\n",
            "2022-08-26 23:12:37.544338 400 0.7903550267219543\n",
            "2022-08-26 23:14:37.012243 500 0.4953688383102417\n",
            "2022-08-26 23:16:36.204740 600 0.7366675138473511\n",
            "2022-08-26 23:18:35.692710 700 0.7197340726852417\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.76      0.84      9910\n",
            "           1       0.27      0.63      0.38      1450\n",
            "\n",
            "    accuracy                           0.74     11360\n",
            "   macro avg       0.60      0.69      0.61     11360\n",
            "weighted avg       0.85      0.74      0.78     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.81      0.86      2515\n",
            "           1       0.25      0.50      0.34       325\n",
            "\n",
            "    accuracy                           0.77      2840\n",
            "   macro avg       0.59      0.66      0.60      2840\n",
            "weighted avg       0.85      0.77      0.80      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch29.pt\n",
            "Epoch 30\n",
            "710\n",
            "2022-08-26 23:19:28.966707 0 0.9040123224258423\n",
            "2022-08-26 23:21:29.514952 100 0.49688634276390076\n",
            "2022-08-26 23:23:30.775452 200 0.4473686218261719\n",
            "2022-08-26 23:25:31.605231 300 0.6642608046531677\n",
            "2022-08-26 23:27:32.010346 400 0.6471015214920044\n",
            "2022-08-26 23:29:31.462750 500 0.7160589694976807\n",
            "2022-08-26 23:31:30.989185 600 0.5099863409996033\n",
            "2022-08-26 23:33:30.598147 700 0.9360167980194092\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.75      0.83      9910\n",
            "           1       0.27      0.63      0.38      1450\n",
            "\n",
            "    accuracy                           0.74     11360\n",
            "   macro avg       0.60      0.69      0.61     11360\n",
            "weighted avg       0.85      0.74      0.78     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.74      0.83      2515\n",
            "           1       0.23      0.58      0.33       325\n",
            "\n",
            "    accuracy                           0.72      2840\n",
            "   macro avg       0.58      0.66      0.58      2840\n",
            "weighted avg       0.85      0.72      0.77      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch30.pt\n",
            "Epoch 31\n",
            "710\n",
            "2022-08-26 23:34:23.126111 0 0.6466202735900879\n",
            "2022-08-26 23:36:23.788376 100 0.45931223034858704\n",
            "2022-08-26 23:38:23.880823 200 0.5707412958145142\n",
            "2022-08-26 23:40:24.105599 300 0.6324093341827393\n",
            "2022-08-26 23:42:24.197778 400 0.6034098267555237\n",
            "2022-08-26 23:44:24.599503 500 0.5257675647735596\n",
            "2022-08-26 23:46:24.839517 600 0.5369293093681335\n",
            "2022-08-26 23:48:24.782032 700 0.45971980690956116\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.74      0.82      9910\n",
            "           1       0.26      0.64      0.37      1450\n",
            "\n",
            "    accuracy                           0.72     11360\n",
            "   macro avg       0.60      0.69      0.60     11360\n",
            "weighted avg       0.85      0.72      0.77     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.84      0.88      2515\n",
            "           1       0.25      0.40      0.30       325\n",
            "\n",
            "    accuracy                           0.79      2840\n",
            "   macro avg       0.58      0.62      0.59      2840\n",
            "weighted avg       0.84      0.79      0.81      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch31.pt\n",
            "Epoch 32\n",
            "710\n",
            "2022-08-26 23:49:17.288912 0 0.4830784499645233\n",
            "2022-08-26 23:51:17.946988 100 0.4421205222606659\n",
            "2022-08-26 23:53:17.935440 200 0.3566727042198181\n",
            "2022-08-26 23:55:18.033608 300 0.43943071365356445\n",
            "2022-08-26 23:57:17.985790 400 0.4051206707954407\n",
            "2022-08-26 23:59:17.986097 500 0.5439180135726929\n",
            "2022-08-27 00:01:17.903255 600 0.6820248961448669\n",
            "2022-08-27 00:03:17.910547 700 0.6859813928604126\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.75      0.83      9910\n",
            "           1       0.27      0.64      0.38      1450\n",
            "\n",
            "    accuracy                           0.73     11360\n",
            "   macro avg       0.60      0.69      0.60     11360\n",
            "weighted avg       0.85      0.73      0.77     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.84      0.88      2515\n",
            "           1       0.26      0.43      0.32       325\n",
            "\n",
            "    accuracy                           0.79      2840\n",
            "   macro avg       0.59      0.64      0.60      2840\n",
            "weighted avg       0.84      0.79      0.81      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch32.pt\n",
            "Epoch 33\n",
            "710\n",
            "2022-08-27 00:04:10.450876 0 0.5797165632247925\n",
            "2022-08-27 00:06:11.039804 100 0.49852678179740906\n",
            "2022-08-27 00:08:10.991088 200 0.6258847117424011\n",
            "2022-08-27 00:10:10.998679 300 0.5762304663658142\n",
            "2022-08-27 00:12:10.825307 400 0.5200272798538208\n",
            "2022-08-27 00:14:09.981824 500 0.6664218306541443\n",
            "2022-08-27 00:16:09.348826 600 0.5934472680091858\n",
            "2022-08-27 00:18:08.974339 700 0.4660149812698364\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.74      0.82      9910\n",
            "           1       0.25      0.61      0.36      1450\n",
            "\n",
            "    accuracy                           0.72     11360\n",
            "   macro avg       0.59      0.68      0.59     11360\n",
            "weighted avg       0.84      0.72      0.76     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.85      0.89      2515\n",
            "           1       0.27      0.43      0.33       325\n",
            "\n",
            "    accuracy                           0.80      2840\n",
            "   macro avg       0.60      0.64      0.61      2840\n",
            "weighted avg       0.85      0.80      0.82      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch33.pt\n",
            "Epoch 34\n",
            "710\n",
            "2022-08-27 00:19:01.436906 0 0.4035482108592987\n",
            "2022-08-27 00:21:01.976484 100 0.6076259613037109\n",
            "2022-08-27 00:23:01.850503 200 0.5415152907371521\n",
            "2022-08-27 00:25:01.759294 300 0.4790568947792053\n",
            "2022-08-27 00:27:01.393725 400 0.5754929184913635\n",
            "2022-08-27 00:29:00.731647 500 0.606518566608429\n",
            "2022-08-27 00:30:59.757924 600 0.5562675595283508\n",
            "2022-08-27 00:32:58.882058 700 0.6538461446762085\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.75      0.83      9910\n",
            "           1       0.27      0.64      0.38      1450\n",
            "\n",
            "    accuracy                           0.73     11360\n",
            "   macro avg       0.60      0.69      0.60     11360\n",
            "weighted avg       0.85      0.73      0.77     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.60      0.74      2515\n",
            "           1       0.19      0.73      0.30       325\n",
            "\n",
            "    accuracy                           0.62      2840\n",
            "   macro avg       0.57      0.67      0.52      2840\n",
            "weighted avg       0.86      0.62      0.69      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch34.pt\n",
            "Epoch 35\n",
            "710\n",
            "2022-08-27 00:33:51.337748 0 0.5173385739326477\n",
            "2022-08-27 00:35:51.625751 100 0.49380433559417725\n",
            "2022-08-27 00:37:52.398458 200 0.6074845194816589\n",
            "2022-08-27 00:39:52.921578 300 0.4355613589286804\n",
            "2022-08-27 00:41:52.831592 400 0.8573585748672485\n",
            "2022-08-27 00:43:52.965470 500 0.5013768076896667\n",
            "2022-08-27 00:45:52.234093 600 0.4484025835990906\n",
            "2022-08-27 00:47:52.287349 700 0.48671287298202515\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.74      0.83      9910\n",
            "           1       0.27      0.65      0.38      1450\n",
            "\n",
            "    accuracy                           0.73     11360\n",
            "   macro avg       0.60      0.70      0.60     11360\n",
            "weighted avg       0.85      0.73      0.77     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.78      0.84      2515\n",
            "           1       0.22      0.48      0.30       325\n",
            "\n",
            "    accuracy                           0.74      2840\n",
            "   macro avg       0.57      0.63      0.57      2840\n",
            "weighted avg       0.84      0.74      0.78      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch35.pt\n",
            "Epoch 36\n",
            "710\n",
            "2022-08-27 00:48:44.759046 0 0.5360665917396545\n",
            "2022-08-27 00:50:45.149157 100 0.737514317035675\n",
            "2022-08-27 00:52:45.051642 200 0.5864703059196472\n",
            "2022-08-27 00:54:44.926898 300 0.5450230240821838\n",
            "2022-08-27 00:56:44.781365 400 0.6856803297996521\n",
            "2022-08-27 00:58:44.781414 500 0.5336607098579407\n",
            "2022-08-27 01:00:44.657848 600 0.6445322632789612\n",
            "2022-08-27 01:02:44.107764 700 0.42425277829170227\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.76      0.84      9910\n",
            "           1       0.27      0.60      0.37      1450\n",
            "\n",
            "    accuracy                           0.74     11360\n",
            "   macro avg       0.60      0.68      0.60     11360\n",
            "weighted avg       0.84      0.74      0.78     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.84      0.88      2515\n",
            "           1       0.26      0.45      0.33       325\n",
            "\n",
            "    accuracy                           0.79      2840\n",
            "   macro avg       0.59      0.64      0.61      2840\n",
            "weighted avg       0.85      0.79      0.82      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch36.pt\n",
            "Epoch 37\n",
            "710\n",
            "2022-08-27 01:03:36.489154 0 0.5307765007019043\n",
            "2022-08-27 01:05:36.981926 100 0.5271543264389038\n",
            "2022-08-27 01:07:36.810318 200 0.6671828031539917\n",
            "2022-08-27 01:09:36.770565 300 0.6305866837501526\n",
            "2022-08-27 01:11:36.655201 400 0.4734283685684204\n",
            "2022-08-27 01:13:36.642908 500 0.4944182336330414\n",
            "2022-08-27 01:15:36.601304 600 0.6146843433380127\n",
            "2022-08-27 01:17:36.820662 700 0.7374917268753052\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.76      0.84      9910\n",
            "           1       0.27      0.63      0.38      1450\n",
            "\n",
            "    accuracy                           0.74     11360\n",
            "   macro avg       0.60      0.69      0.61     11360\n",
            "weighted avg       0.85      0.74      0.78     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.78      0.85      2515\n",
            "           1       0.25      0.55      0.34       325\n",
            "\n",
            "    accuracy                           0.75      2840\n",
            "   macro avg       0.59      0.67      0.60      2840\n",
            "weighted avg       0.85      0.75      0.79      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch37.pt\n",
            "Epoch 38\n",
            "710\n",
            "2022-08-27 01:18:29.343940 0 0.6755382418632507\n",
            "2022-08-27 01:20:29.750225 100 0.6863802075386047\n",
            "2022-08-27 01:22:29.675059 200 0.4468111991882324\n",
            "2022-08-27 01:24:29.184953 300 0.5015073418617249\n",
            "2022-08-27 01:26:28.626512 400 0.4994093179702759\n",
            "2022-08-27 01:28:28.241195 500 0.4276469647884369\n",
            "2022-08-27 01:30:27.784759 600 0.6826255321502686\n",
            "2022-08-27 01:32:27.512235 700 0.646884024143219\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.77      0.84      9910\n",
            "           1       0.28      0.61      0.38      1450\n",
            "\n",
            "    accuracy                           0.75     11360\n",
            "   macro avg       0.61      0.69      0.61     11360\n",
            "weighted avg       0.85      0.75      0.78     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.78      0.85      2515\n",
            "           1       0.24      0.54      0.33       325\n",
            "\n",
            "    accuracy                           0.75      2840\n",
            "   macro avg       0.59      0.66      0.59      2840\n",
            "weighted avg       0.85      0.75      0.79      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch38.pt\n",
            "Epoch 39\n",
            "710\n",
            "2022-08-27 01:33:19.892429 0 0.4229920208454132\n",
            "2022-08-27 01:35:20.028556 100 0.41574254631996155\n",
            "2022-08-27 01:37:20.252158 200 0.5428794622421265\n",
            "2022-08-27 01:39:20.379197 300 0.6249021887779236\n",
            "2022-08-27 01:41:20.101163 400 0.6556114554405212\n",
            "2022-08-27 01:43:19.740619 500 0.433601051568985\n",
            "2022-08-27 01:45:19.461368 600 0.6751106977462769\n",
            "2022-08-27 01:47:19.248957 700 0.5563525557518005\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.76      0.84      9910\n",
            "           1       0.27      0.62      0.38      1450\n",
            "\n",
            "    accuracy                           0.74     11360\n",
            "   macro avg       0.60      0.69      0.61     11360\n",
            "weighted avg       0.85      0.74      0.78     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.77      0.84      2515\n",
            "           1       0.21      0.49      0.30       325\n",
            "\n",
            "    accuracy                           0.73      2840\n",
            "   macro avg       0.57      0.63      0.57      2840\n",
            "weighted avg       0.84      0.73      0.77      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch39.pt\n",
            "Epoch 40\n",
            "710\n",
            "2022-08-27 01:48:11.625487 0 0.5428501963615417\n",
            "2022-08-27 01:50:11.340915 100 0.5342564582824707\n",
            "2022-08-27 01:52:11.089410 200 0.6878861784934998\n",
            "2022-08-27 01:54:10.492233 300 0.7764784097671509\n",
            "2022-08-27 01:56:09.874760 400 0.5820976495742798\n",
            "2022-08-27 01:58:09.337193 500 0.6385116577148438\n",
            "2022-08-27 02:00:08.742600 600 0.5366132259368896\n",
            "2022-08-27 02:02:08.113409 700 0.8747086524963379\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.76      0.84      9910\n",
            "           1       0.28      0.62      0.39      1450\n",
            "\n",
            "    accuracy                           0.75     11360\n",
            "   macro avg       0.61      0.69      0.61     11360\n",
            "weighted avg       0.85      0.75      0.78     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.69      0.79      2515\n",
            "           1       0.20      0.62      0.30       325\n",
            "\n",
            "    accuracy                           0.68      2840\n",
            "   macro avg       0.57      0.65      0.55      2840\n",
            "weighted avg       0.85      0.68      0.74      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch40.pt\n",
            "Epoch 41\n",
            "710\n",
            "2022-08-27 02:03:00.699986 0 0.5474697351455688\n",
            "2022-08-27 02:05:00.565505 100 0.5544518828392029\n",
            "2022-08-27 02:06:59.967570 200 0.5122206211090088\n",
            "2022-08-27 02:08:59.766399 300 0.607527494430542\n",
            "2022-08-27 02:10:59.126626 400 0.7420586347579956\n",
            "2022-08-27 02:12:57.959766 500 0.6823049783706665\n",
            "2022-08-27 02:14:56.729542 600 0.4110026955604553\n",
            "2022-08-27 02:16:55.608840 700 0.46910232305526733\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.76      0.84      9910\n",
            "           1       0.28      0.63      0.39      1450\n",
            "\n",
            "    accuracy                           0.75     11360\n",
            "   macro avg       0.61      0.70      0.61     11360\n",
            "weighted avg       0.85      0.75      0.78     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.83      0.87      2515\n",
            "           1       0.23      0.39      0.29       325\n",
            "\n",
            "    accuracy                           0.78      2840\n",
            "   macro avg       0.57      0.61      0.58      2840\n",
            "weighted avg       0.83      0.78      0.80      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch41.pt\n",
            "Epoch 42\n",
            "710\n",
            "2022-08-27 02:17:47.867875 0 0.5442954897880554\n",
            "2022-08-27 02:19:47.249162 100 0.36088699102401733\n",
            "2022-08-27 02:21:46.080023 200 0.5368602275848389\n",
            "2022-08-27 02:23:44.805439 300 0.6751334071159363\n",
            "2022-08-27 02:25:43.552340 400 0.46264106035232544\n",
            "2022-08-27 02:27:42.487287 500 0.42552420496940613\n",
            "2022-08-27 02:29:41.740532 600 0.5048046708106995\n",
            "2022-08-27 02:31:41.196334 700 0.3903420865535736\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.76      0.84      9910\n",
            "           1       0.28      0.63      0.39      1450\n",
            "\n",
            "    accuracy                           0.75     11360\n",
            "   macro avg       0.61      0.70      0.61     11360\n",
            "weighted avg       0.85      0.75      0.78     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.78      0.85      2515\n",
            "           1       0.24      0.54      0.33       325\n",
            "\n",
            "    accuracy                           0.75      2840\n",
            "   macro avg       0.59      0.66      0.59      2840\n",
            "weighted avg       0.85      0.75      0.79      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch42.pt\n",
            "Epoch 43\n",
            "710\n",
            "2022-08-27 02:32:33.629650 0 0.6413643956184387\n",
            "2022-08-27 02:34:33.683400 100 0.502227783203125\n",
            "2022-08-27 02:36:33.179505 200 0.8266699910163879\n",
            "2022-08-27 02:38:32.582326 300 0.5047491788864136\n",
            "2022-08-27 02:40:31.976818 400 0.5297030210494995\n",
            "2022-08-27 02:42:31.231288 500 0.4393683969974518\n",
            "2022-08-27 02:44:30.599604 600 0.5099318027496338\n",
            "2022-08-27 02:46:29.962169 700 0.4722215533256531\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.75      0.83      9910\n",
            "           1       0.27      0.64      0.38      1450\n",
            "\n",
            "    accuracy                           0.74     11360\n",
            "   macro avg       0.60      0.70      0.61     11360\n",
            "weighted avg       0.85      0.74      0.78     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.87      0.89      2515\n",
            "           1       0.26      0.34      0.29       325\n",
            "\n",
            "    accuracy                           0.81      2840\n",
            "   macro avg       0.58      0.61      0.59      2840\n",
            "weighted avg       0.84      0.81      0.82      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch43.pt\n",
            "Epoch 44\n",
            "710\n",
            "2022-08-27 02:47:22.303156 0 0.5806395411491394\n",
            "2022-08-27 02:49:22.009960 100 0.5783671736717224\n",
            "2022-08-27 02:51:21.457637 200 0.7100819945335388\n",
            "2022-08-27 02:53:20.327268 300 0.565389096736908\n",
            "2022-08-27 02:55:19.041360 400 0.622846245765686\n",
            "2022-08-27 02:57:17.797235 500 0.7540739178657532\n",
            "2022-08-27 02:59:16.588879 600 0.5409751534461975\n",
            "2022-08-27 03:01:15.730968 700 0.6639840006828308\n",
            "Results\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.76      0.84      9910\n",
            "           1       0.28      0.65      0.39      1450\n",
            "\n",
            "    accuracy                           0.74     11360\n",
            "   macro avg       0.61      0.70      0.62     11360\n",
            "weighted avg       0.85      0.74      0.78     11360\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.77      0.84      2515\n",
            "           1       0.23      0.52      0.32       325\n",
            "\n",
            "    accuracy                           0.74      2840\n",
            "   macro avg       0.58      0.65      0.58      2840\n",
            "weighted avg       0.85      0.74      0.78      2840\n",
            "\n",
            "Model saved to ==> /content/drive/MyDrive/doutorado/diag_trat_saving/all_br//model-bert_twitter-A-sel-all_br-epoch44.pt\n",
            "Epoch 45\n",
            "710\n",
            "2022-08-27 03:02:08.059307 0 0.7383228540420532\n",
            "2022-08-27 03:04:08.224176 100 0.630810558795929\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-8c5b1f244da5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mrun_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-ae9ee08d8fc1>\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m(task, sel, model_name)\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0mtrain_loss_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;31m# Backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m                 \u001b[0;31m# Update parameters and take a step using the computed gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Run this cell to train the selected models\n",
        "\n",
        "import itertools\n",
        "\n",
        "tasks = ['A', 'D'] # 'A' to anxiety and 'D' to depression\n",
        "selection = ['all_br'] # The selection of data\n",
        "models = ['moe_br'] # model name\n",
        "\n",
        "for task, sel, model_name in itertools.product(tasks, selection, models):\n",
        "    run_train(task, sel, model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmxOZjV-CokT"
      },
      "outputs": [],
      "source": [
        "import re \n",
        "import gc\n",
        "import itertools\n",
        "\n",
        "# Make the prediction with a specific model on 50 random sequences for each timeline\n",
        "def make_prediction(model, dataloader_, model_name):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # validation loop\n",
        "        all_pred = []\n",
        "        for _ in range(50):\n",
        "            pred, real = [], []\n",
        "            for j, batch in enumerate(dataloader_):\n",
        "                atts = torch.stack([aa[0]['tokens'] for aa in batch]).to(device)\n",
        "                masks = torch.stack([aa[0]['mask'] for aa in batch]).to(device)\n",
        "                \n",
        "                if model_name == 'ens':\n",
        "                    outputs, model_outputs = model(atts, masks)\n",
        "                else:\n",
        "                    outputs = model(atts, masks)\n",
        "                # outputs = model(atts, masks)\n",
        "\n",
        "                pred = pred + outputs.cpu().argmax(1).tolist()\n",
        "                real = real + [b[1] for b in batch]\n",
        "            print(classification_report(real, pred))\n",
        "            all_pred.append(pred)\n",
        "\n",
        "        p = (np.array(all_pred).mean(0) > 0.5).astype(int)\n",
        "        print(\"*\" * 20, '\\nALL')\n",
        "        print(classification_report(real, p))\n",
        "        print(\"*\" * 20)\n",
        "\n",
        "\n",
        "# Receives the task, data selection and model name\n",
        "def evaluate_results(task, sel, model_name):\n",
        "    gc.collect()\n",
        "    device = 'cuda'\n",
        "    if model_name == 'moe':\n",
        "        model = MoE(device)\n",
        "    elif model_name == 'moe_br':\n",
        "        model = MoEBR(device)\n",
        "\n",
        "    else:\n",
        "        raise Exception('Model not defined')\n",
        "\n",
        "    model.to(device)\n",
        "    file_path = f'/content/drive/MyDrive/doutorado/diag_trat_saving/{sel}/'\n",
        "    files = os.listdir(file_path)\n",
        "    regex = re.compile(f'model-{model_name}-{task}-sel-{sel}-epoch')\n",
        "    files = [f for f in files if regex.search(f)]\n",
        "    df_train, df_test = load_convert(task, sel)    \n",
        "    # tokenizer = BertTokenizerFast.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
        "    tokenizer = BertTokenizerFast.from_pretrained('pablocosta/bertweet-br-base-uncased')\n",
        "    X_train, y_train = get_tokens_mask_dates_split(df_train['Text'].tolist(), df_train['label'].tolist(), tokenizer, 'train', task, sel)\n",
        "    # X_test, y_test = get_tokens_mask_dates_split(df_test['Text'].tolist(), df_test['label'].tolist(), tokenizer, 'test', task, sel)    \n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "    del X_train\n",
        "    del y_train\n",
        "    del df_test\n",
        "    gc.collect()\n",
        "    dataloader_val = get_dataloader(X_val, y_val, False)\n",
        "    # dataloader_test = get_dataloader(X_test, y_test, False)\n",
        "    \n",
        "    # define the epoch you want to run\n",
        "    for f in [15, 18, 19, 29, 31, 33, 36]:\n",
        "        path = f'{file_path}model-{model_name}-{task}-sel-all_br-epoch{f}.pt'\n",
        "        print('*' * 20, f'\\n{path}')\n",
        "        try:\n",
        "            load_checkpoint(f'{path}', model)\n",
        "        except:\n",
        "            continue\n",
        "        model.eval()\n",
        "        make_prediction(model, dataloader_val, model_name)\n",
        "    del df_train\n",
        "    del X_val\n",
        "    del y_val\n",
        "    del dataloader_val\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "\n",
        "# tasks = ['A']\n",
        "# selection = ['all_br']\n",
        "# models = ['bert_twitter']\n",
        "\n",
        "# for task, sel, model_name in itertools.product(tasks, selection, models):\n",
        "#     # print(task, sel, model_name)\n",
        "#     evaluate_results(task, sel, model_name)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyN8dp+y4jHWmNnhnGOzZPTq",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "067995218ac6415b9c56ce11237f69f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0689ee863fa74fd0a38b1ff85d8794ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b63e4edeff643a7abe08fb7c21654ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ddf361a2eec49e893963ab73101a884": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8081a1975dc34de7b4b050ebff5d8988",
            "placeholder": "​",
            "style": "IPY_MODEL_fd15e70a88444a9f8a5d9fcdf2be4bdd",
            "value": " 518M/518M [00:28&lt;00:00, 20.8MB/s]"
          }
        },
        "3fb2eb8d5f7949dd9a3f1e460708c4cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bee93f89c794ced8bf564e14372f448",
            "placeholder": "​",
            "style": "IPY_MODEL_067995218ac6415b9c56ce11237f69f4",
            "value": "Downloading config.json: 100%"
          }
        },
        "4a258085d9a04321bc7b984f76cf36ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5096569d0b8c49c0b2f63079191dbb4f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "516cfca1c8c34ffdbe9984dd074d68f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6eefa2cc98864ae38f35d62ef959692b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1d1147c61d3460790d639919d55153a",
            "max": 384,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0689ee863fa74fd0a38b1ff85d8794ae",
            "value": 384
          }
        },
        "7bee93f89c794ced8bf564e14372f448": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8081a1975dc34de7b4b050ebff5d8988": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94e6e974927b4a749e5d84f2f94fa011": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b63e4edeff643a7abe08fb7c21654ca",
            "placeholder": "​",
            "style": "IPY_MODEL_4a258085d9a04321bc7b984f76cf36ec",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "a0c7c297b63a4794a9970e0c94fd72dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5096569d0b8c49c0b2f63079191dbb4f",
            "placeholder": "​",
            "style": "IPY_MODEL_516cfca1c8c34ffdbe9984dd074d68f4",
            "value": " 384/384 [00:00&lt;00:00, 16.6kB/s]"
          }
        },
        "b23f7718273c42b4918630a61c15beb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_beb7d3ed5a584afb87e93baf3545c569",
            "max": 543488355,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc90d0167cc7486882f01c3e3285d174",
            "value": 543488355
          }
        },
        "b8dbd476b52d421a9c848676dfda2ee7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_94e6e974927b4a749e5d84f2f94fa011",
              "IPY_MODEL_b23f7718273c42b4918630a61c15beb8",
              "IPY_MODEL_2ddf361a2eec49e893963ab73101a884"
            ],
            "layout": "IPY_MODEL_f10bdf4dd40543028ecf26d34c2597d3"
          }
        },
        "bc90d0167cc7486882f01c3e3285d174": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "beb7d3ed5a584afb87e93baf3545c569": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1d1147c61d3460790d639919d55153a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce0b346f292b4b51bb90fe5977a97e4e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e86c88a4a2a04972b9a604f7f0b01fae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3fb2eb8d5f7949dd9a3f1e460708c4cf",
              "IPY_MODEL_6eefa2cc98864ae38f35d62ef959692b",
              "IPY_MODEL_a0c7c297b63a4794a9970e0c94fd72dc"
            ],
            "layout": "IPY_MODEL_ce0b346f292b4b51bb90fe5977a97e4e"
          }
        },
        "f10bdf4dd40543028ecf26d34c2597d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd15e70a88444a9f8a5d9fcdf2be4bdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}